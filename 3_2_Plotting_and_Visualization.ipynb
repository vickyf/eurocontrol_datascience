{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rcParams\n",
    "rcParams[\"figure.figsize\"] = 12,8\n",
    "\n",
    "# Set some Pandas options\n",
    "#pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Visualization\n",
    "\n",
    "There are a handful of third-party Python packages that are suitable for creating scientific plots and visualizations. These include packages like:\n",
    "\n",
    "* matplotlib\n",
    "* seaborn\n",
    "* Bokeh\n",
    "* ...\n",
    "\n",
    "Here, we will focus excelusively on matplotlib and the high-level plotting availabel within pandas. It is currently the most robust and feature-rich package available.\n",
    "\n",
    "### Visual representation of data\n",
    "\n",
    "We require plots, charts and other statistical graphics for the written communication of quantitative ideas.\n",
    "\n",
    "They allow us to more easily convey relationships and reveal deviations from patterns.\n",
    "\n",
    "Gelman and Unwin 2011:\n",
    "\n",
    "> A well-designed graph can display more information than a table of the same size, and more information than numbers embedded in text. Graphical displays allow and encourage direct visual comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.random.normal(size=100), np.random.normal(size=100), 'ro');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot simply shows two sets of random numbers taken from a normal distribution plotted against one another. The `'ro'` argument is a shorthand argument telling matplotlib that I wanted the points represented as red circles.\n",
    "\n",
    "This plot was expedient. We can exercise a little more control by breaking the plotting into a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2,figsize=(6,3))\n",
    "ax[0].set_xlabel('some random numbers')\n",
    "ax[0].set_ylabel('more random numbers')\n",
    "ax[0].set_title(\"Random scatterplot\")\n",
    "ax[0].plot(np.random.normal(size=100), np.random.normal(size=100), 'r.')\n",
    "\n",
    "ax[1].hist(np.random.normal(size=100), bins=15)\n",
    "ax[1].set_xlabel('sample')\n",
    "ax[1].set_ylabel('cumulative sum')\n",
    "ax[1].set_title(\"Normal distrubution\")\n",
    "f.tight_layout()\n",
    "f.savefig(\"normalvars.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib is a relatively low-level plotting package, relative to others. It makes very few assumptions about what constitutes good layout (by design), but has a lot of flexiblility to allow the user to completely customize the look of the output.\n",
    "\n",
    "## Plotting in Pandas\n",
    "\n",
    "On the other hand, Pandas includes methods for DataFrame and Series objects that are relatively high-level, and that make reasonable assumptions about how the plot should look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals = pd.Series(np.random.normal(size=10))\n",
    "normals.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by default a line plot is drawn, and a light grid is included. All of this can be changed, however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normals.cumsum().plot(grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.DataFrame({'normal': np.random.normal(size=100), \n",
    "                          'gamma': np.random.gamma(1, size=100), \n",
    "                          'poisson': np.random.poisson(size=100)})\n",
    "variables.cumsum(0).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration of the high-level nature of Pandas plots, we can split multiple series into subplots with a single argument for `plot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.cumsum(0).plot(subplots=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we may want to have some series displayed on the secondary y-axis, which can allow for greater detail and less empty space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.cumsum(0).plot(secondary_y='normal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would like a little more control, we can use matplotlib's `subplots` function directly, and manually assign plots to its axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "for i,var in enumerate(['normal','gamma','poisson']):\n",
    "    variables[var].cumsum(0).plot(ax=axes[i], title=var)\n",
    "axes[0].set_ylabel('cumulative sum');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plots\n",
    "\n",
    "Bar plots are useful for displaying and comparing measurable quantities, such as counts or volumes. In Pandas, we just use the `plot` method with a `kind='bar'` argument.\n",
    "\n",
    "For this series of examples, let's load up the Titanic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_excel(\"data/titanic.xls\", \"titanic\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby('pclass').survived.sum().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.groupby(['sex','pclass']).survived.sum().plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_counts = pd.crosstab([titanic.pclass, titanic.sex], titanic.survived.astype(bool))\n",
    "death_counts.plot(kind='bar', stacked=True, color=['black','gold'], grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of comparing the groups is to look at the survival *rate*, by adjusting for the number of people in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_counts.div(death_counts.sum(1).astype(float), axis=0).plot(kind='barh', stacked=True, color=['black','gold']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "Frequenfly it is useful to look at the *distribution* of data before you analyze it. Histograms are a sort of bar graph that displays relative frequencies of data values; hence, the y-axis is always some measure of frequency. This can either be raw counts of values or scaled proportions.\n",
    "\n",
    "For example, we might want to see how the fares were distributed aboard the titanic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fare.hist(grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hist` method puts the continuous fare values into **bins**, trying to make a sensible d√©cision about how many bins to use (or equivalently, how wide the bins are). We can override the default value (10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fare.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are algorithms for determining an \"optimal\" number of bins, each of which varies somehow with the number of observations in the data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sturges = lambda n: int(np.log2(n) + 1)\n",
    "square_root = lambda n: int(np.sqrt(n))\n",
    "from scipy.stats import kurtosis\n",
    "doanes = lambda data: int(1 + np.log(len(data)) + np.log(1 + kurtosis(data) * (len(data) / 6.) ** 0.5))\n",
    "\n",
    "n = len(titanic)\n",
    "sturges(n), square_root(n), doanes(titanic.fare.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fare.hist(bins=doanes(titanic.fare.dropna()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **density plot** is similar to a histogram in that it describes the distribution of the underlying data, but rather than being a pure empirical representation, it is an *estimate* of the underlying \"true\" distribution. As a result, it is smoothed into a continuous line plot. We create them in Pandas using the `plot` method with `kind='kde'`, where `kde` stands for **kernel density estimate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fare.dropna().plot(kind='kde', xlim=(0,600));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, histograms and density plots are shown together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.fare.hist(bins=doanes(titanic.fare.dropna()), normed=True, color='lightseagreen')\n",
    "titanic.fare.dropna().plot(kind='kde', xlim=(0,600), style='r--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we had to normalize the histogram (`normed=True`), since the kernel density is normalized by definition (it is a probability distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore kernel density estimates more in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots\n",
    "\n",
    "A different way of visualizing the distribution of data is the boxplot, which is a display of common quantiles; these are typically the quartiles and the lower and upper 5 percent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.boxplot(column='fare', by='pclass', grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the box plot as viewing the distribution from above. The blue crosses are \"outlier\" points that occur outside the extreme quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to add additional information to a boxplot is to overlay the actual data; this is generally most suitable with small- or moderate-sized data series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = titanic.boxplot(column='age', by='pclass', grid=False)\n",
    "for i in [1,2,3]:\n",
    "    y = titanic.age[titanic.pclass==i].dropna()\n",
    "    # Add some random \"jitter\" to the x-axis\n",
    "    x = np.random.normal(i, 0.04, size=len(y))\n",
    "    plt.plot(x, y, 'r.', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data are dense, a couple of tricks used above help the visualization:\n",
    "\n",
    "1. reducing the alpha level to make the points partially transparent\n",
    "2. adding random \"jitter\" along the x-axis to avoid overstriking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Using the Titanic data, create kernel density estimate plots of the age distributions of survivors and victims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load 3_Exploratory_Data_Analysis/titanic_kde.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots\n",
    "\n",
    "To look at how Pandas does scatterplots, let's reload the baseball sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"data/baseball.csv\")\n",
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplots are useful for data exploration, where we seek to uncover relationships among variables. There are no scatterplot methods for Series or DataFrame objects; we must instead use the matplotlib function `scatter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(baseball.ab, baseball.h)\n",
    "plt.xlim(0, 700); plt.ylim(0, 200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add additional information to scatterplots by assigning variables to either the size of the symbols or their colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(baseball.ab, baseball.h, s=baseball.hr*10, alpha=0.5)\n",
    "plt.xlim(0, 700); plt.ylim(0, 200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Create a similar scatterplot of 'baseball.ab' against 'baseball.h', but this time let the color change based on the variable 'baseball.hr'. Keep the size of the symbol at 40. Select an appropriate colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load 3_Exploratory_Data_Analysis/baseball_color.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view scatterplots of a large numbers of variables simultaneously, we can use the `scatter_matrix` function that was recently added to Pandas. It generates a matrix of pair-wise scatterplots, optionally with histograms or kernel density estimates on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "_ = scatter_matrix(baseball.loc[:,'r':'sb'], figsize=(12,8), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trellis Plots\n",
    "\n",
    "Trellis plots are not supported anymore by pandas, so use the **seaborn library** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "tips_data = pd.read_csv('data/tips.csv')\n",
    "g = sns.FacetGrid(tips_data, row=\"sex\", col=\"smoker\")\n",
    "g.map(plt.hist, \"total_bill\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(tips_data, row=\"sex\", col=\"smoker\")\n",
    "g.map(sns.kdeplot, \"total_bill\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(tips_data, row=\"sex\", col=\"smoker\")\n",
    "g.map(plt.scatter, \"total_bill\", \"tip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing a regression line, using the dedicated **seaborn regplot function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "g = sns.FacetGrid(tips_data, row=\"sex\", col=\"smoker\", margin_titles=True)\n",
    "g.map(sns.regplot, \"total_bill\", \"tip\", order=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/fonnesbeck/statistical-analysis-python-tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
