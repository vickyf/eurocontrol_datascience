{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised  Learning\n",
    "\n",
    "Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data **without labeled responses**. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find **hidden patterns** or grouping in data.\n",
    "\n",
    "Note that because of this there is no such thing as a training and test set. We namely have no idea what the *correct* clustering looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "One of the most popular clustering algorithms is K-means. The KMeans algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares. This algorithm requires the number of clusters to be specified. It scales well to large number of samples and has been used across a large range of application areas in many different fields.\n",
    "\n",
    "Though normally we have no access to the true clusters, let's use the iris database so have some baseline to compare how well this algorithm performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris) \n",
    "\n",
    "print(k_means.labels_[::10])\n",
    "\n",
    "print(y_iris[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when more clusters are used? Plot the groundtrugh, n_clusters=3 and n_clusters=4 below (2 dimensions are enough):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 5_Machine_Learning/kmeans.py\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(20,5))\n",
    "ax[0].scatter(X_iris[:,0], X_iris[:,1], c=y_iris)\n",
    "ax[0].set_title(\"ground truth\")\n",
    "ax[1].scatter(X_iris[:,0], X_iris[:,1], c=k_means.labels_)\n",
    "ax[1].set_title(\"kmeans: 2 components\")\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=4)\n",
    "k_means.fit(X_iris)\n",
    "\n",
    "ax[2].scatter(X_iris[:,0], X_iris[:,1], c=k_means.labels_)\n",
    "ax[2].set_title(\"kmeans: 3 components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as we said mostly you do not know what the correct number of clusters is, so how do we find them? For this we need to take a look at Gaussian Mixture models and their extension to Dirichlet Process Models. Unfortunately this is a bit of a more complex topic, so we will not go into it extensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirichlet Process Models\n",
    "\n",
    "Here a quick example though of working code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "from scipy import linalg\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold',\n",
    "                              'darkorange'])\n",
    "\n",
    "# Number of samples per component\n",
    "n_samples = 500\n",
    "\n",
    "# Generate random sample, two components\n",
    "np.random.seed(0)\n",
    "C = np.array([[0., -0.1], [1.7, .4]])\n",
    "X = np.r_[np.dot(np.random.randn(n_samples, 2), C),\n",
    "          .7 * np.random.randn(n_samples, 2) + np.array([-6, 3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Dirichlet process Gaussian mixture using five components\n",
    "dpgmm = mixture.BayesianGaussianMixture(n_components=5,\n",
    "                                        covariance_type='full').fit(X)\n",
    "\n",
    "# n_components: max number of components\n",
    "# covariance_type: shape of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X, Y_, means, covariances, index, title):\n",
    "    plt.figure(figsize=(20,12))\n",
    "    splot = plt.subplot(2, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    plt.xlim(-9., 5.)\n",
    "    plt.ylim(-3., 6.)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(X, dpgmm.predict(X), dpgmm.means_, dpgmm.covariances_, 1,\n",
    "             'Bayesian Gaussian Mixture with a Dirichlet process prior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
